[34m[1mwandb[0m: Detected [huggingface_hub.inference, openai] in use.
[34m[1mwandb[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
[34m[1mwandb[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/
  7%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                                                       | 14/198 [55:52<11:03:44, 216.44s/it]Traceback (most recent call last):
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 3.2255, 'grad_norm': 2.5095419883728027, 'learning_rate': 0.0, 'epoch': 0.01}
{'loss': 3.3459, 'grad_norm': 2.5427489280700684, 'learning_rate': 4e-05, 'epoch': 0.01}
{'loss': 3.2196, 'grad_norm': 2.5221195220947266, 'learning_rate': 8e-05, 'epoch': 0.02}
{'loss': 3.0914, 'grad_norm': 2.552105665206909, 'learning_rate': 0.00012, 'epoch': 0.02}
{'loss': 2.8862, 'grad_norm': 1.7745275497436523, 'learning_rate': 0.00016, 'epoch': 0.03}
{'loss': 2.5941, 'grad_norm': 1.6061099767684937, 'learning_rate': 0.0002, 'epoch': 0.03}
{'loss': 2.4921, 'grad_norm': 1.283079981803894, 'learning_rate': 0.0001989637305699482, 'epoch': 0.04}
{'loss': 2.2854, 'grad_norm': 1.2444850206375122, 'learning_rate': 0.00019792746113989637, 'epoch': 0.04}
{'loss': 2.3082, 'grad_norm': 0.7625889778137207, 'learning_rate': 0.00019689119170984457, 'epoch': 0.05}
{'loss': 2.1962, 'grad_norm': 0.7952146530151367, 'learning_rate': 0.00019585492227979276, 'epoch': 0.05}
{'loss': 2.0377, 'grad_norm': 0.7080395817756653, 'learning_rate': 0.00019481865284974093, 'epoch': 0.06}
{'loss': 2.0087, 'grad_norm': 0.6914846897125244, 'learning_rate': 0.00019378238341968913, 'epoch': 0.06}
{'loss': 1.9896, 'grad_norm': 0.5295285582542419, 'learning_rate': 0.00019274611398963732, 'epoch': 0.07}
{'loss': 1.918, 'grad_norm': 0.5336007475852966, 'learning_rate': 0.0001917098445595855, 'epoch': 0.07}
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1251, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/queue.py", line 180, in get
    self.not_empty.wait(remaining)
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/threading.py", line 331, in wait
    gotit = waiter.acquire(True, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 59114) is killed by signal: Killed.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/liwt/IVCP/unsloth/model.py", line 70, in <module>
    trainer.train()
  File "/home/liwt/IVCP/unsloth/unsloth_compiled_cache/UnslothSFTTrainer.py", line 55, in wrapper
    output = f(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/accelerate/utils/memory.py", line 177, in decorator
    return function(batch_size, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 272, in _fast_inner_training_loop
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/unsloth_zoo/loss_utils.py", line 326, in _unsloth_get_batch_samples
    batch_samples += [next(epoch_iterator)]
                      ^^^^^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/accelerate/data_loader.py", line 579, in __iter__
    next_batch = next(dataloader_iter)
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 708, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1458, in _next_data
    idx, data = self._get_data()
                ^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1410, in _get_data
    success, data = self._try_get_data()
                    ^^^^^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1264, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 59114) exited unexpectedly
Traceback (most recent call last):
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1251, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/queue.py", line 180, in get
    self.not_empty.wait(remaining)
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/threading.py", line 331, in wait
    gotit = waiter.acquire(True, timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 59114) is killed by signal: Killed.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/liwt/IVCP/unsloth/model.py", line 70, in <module>
    trainer.train()
  File "/home/liwt/IVCP/unsloth/unsloth_compiled_cache/UnslothSFTTrainer.py", line 55, in wrapper
    output = f(self, *args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/accelerate/utils/memory.py", line 177, in decorator
    return function(batch_size, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 272, in _fast_inner_training_loop
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/unsloth_zoo/loss_utils.py", line 326, in _unsloth_get_batch_samples
    batch_samples += [next(epoch_iterator)]
                      ^^^^^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/accelerate/data_loader.py", line 579, in __iter__
    next_batch = next(dataloader_iter)
                 ^^^^^^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 708, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1458, in _next_data
    idx, data = self._get_data()
                ^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1410, in _get_data
    success, data = self._try_get_data()
                    ^^^^^^^^^^^^^^^^^^^^
  File "/home/liwt/anaconda3/envs/unsloth_env/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1264, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 59114) exited unexpectedly
